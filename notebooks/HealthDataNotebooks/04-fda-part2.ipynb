{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we'll be using the OpenFDA API to retrieve and plot data sampled at many time periods. We will show some plot types that are useful for near continuous data with hundreds of samples. \n",
    "\n",
    "We will use the openFDA API again to retrieve adverse event data for a number of drugs.  Data will be retrieved for every week over a period of four years.  This means there will be over 200 datapoints.  We then show how to.\n",
    "\n",
    "- **plot line profiles**\n",
    "- **use a smoothing function to reduce noise in the data**\n",
    "- **use a stacked area chart to show relative and absolute trends**\n",
    "- **use a 100% stacked area chart to emphasize uncorrelated trends**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual we start by importing the libraries we will need to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json as js\n",
    "import urllib2 as ulib\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also tell the notebook to render inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining a list of drugs to investigate.  Here we also define a standard figure size. If we want to investigate different drugs later, or change the size of the figures we can come back and change this block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define a list of drugs to investigate\n",
    "drugs=['paxil', 'lexapro', 'hydrocodone', 'xanax']\n",
    "\n",
    "figsize=[10,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a function to get adverse event data that has been reported within a specific time period.  To do this we need to use more features of the OpenFDA API (https://open.fda.gov/drug/event/).  Specifically we want to use the receivedate field to specify a time range to retrieve data for.  First we write and test a block that retrieves adverse event data between two time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drugname='Aspirin'\n",
    "start_date='2009-10-1'\n",
    "end_date='2010-10-1'\n",
    "\n",
    "request_string='https://api.fda.gov/drug/event.json?&search=patient.drug.medicinalproduct:'+str(drugname)+'+AND+receivedate:['+str(start_date)+'+TO+'+str(end_date)+']&count=patient.reaction.reactionmeddrapt.exact'\n",
    "    \n",
    "request=ulib.Request(request_string)\n",
    "\n",
    "# open the url\n",
    "opener = ulib.build_opener()\n",
    "f = opener.open(request)\n",
    "\n",
    "# load as json\n",
    "fda_data=json.load(f)\n",
    "\n",
    "fda_df=pd.DataFrame(fda_data['results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we learn how to retrieve data by time period we put the code into a function so we can re-use it.  It's a good idea to document the function with a small description of the overall purpose and the type and purpose of the inputs and outputs.  So let's do that.\n",
    "\n",
    "`get_event_data`\n",
    "\n",
    "Description: Forms a request string and asks the openFDA API for adverse event info for a drug between two dates. \n",
    "\n",
    "Inputs:\n",
    "\n",
    "- `drugname`: String, name of drug\n",
    "- `start_date`: String representing a date in Y-m-d format.  \n",
    "- `end_date`: String representing a data in Y-m-d format.\n",
    "\n",
    "Return Value: JSON structure representing adverse event info reported for a drug between the start and end dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_event_data(drugname, start_date, end_date):\n",
    "    # form a request\n",
    "    api_key='6OcOelyLSQYJAZlZ8C1XggprPQ5oBx8171k9z0aP'\n",
    "    \n",
    "    request_string='https://api.fda.gov/drug/event.json?api_key='+api_key+'&search=patient.drug.medicinalproduct:'+str(drugname)+'+AND+receivedate:['+str(start_date)+'+TO+'+str(end_date)+']&count=patient.reaction.reactionmeddrapt.exact'\n",
    "    \n",
    "    request=ulib.Request(request_string)\n",
    "\n",
    "    # open the url\n",
    "    opener = ulib.build_opener()\n",
    "    f = opener.open(request)\n",
    "\n",
    "    # load as json\n",
    "    fda_data=simplejson.load(f)\n",
    "    \n",
    "    # return the results\n",
    "    return pd.DataFrame(fda_data['results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a function to calculate the sum total of all adverse events contained in an event list.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_total_adverse_events(event_list):\n",
    "    total=0\n",
    "    for event_info in event_list:\n",
    "        total+=event_info['count']\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next step is optional.  Note the data has previously been saved in the file drug_events.json.  \n",
    "\n",
    "We first define a list of drugs and loop through them.  Then we want to loop through several years of data.  To achieve this we define a start date then loop, incrementing the date by 1 week until we reach the year 2012.  This means we will retrieve data for the years 2008 through 2011 on a weekly basis.  For each week we call the function to request the adverse event data and the function to calculate the total number of adverse events.  We then save the data to a dictionary using the drug name as the key. \n",
    "\n",
    "Note: In the loop we call the API over 200 times for four different drugs.  Thus 800 api calls are made.  OpenFDA has a limit of 240 calls per minute.  Depending on the speed of connection this loop may violate the api call limit.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01 00:00:00 246\n",
      "2008-01-15 00:00:00 188\n",
      "2008-01-29 00:00:00 2054\n",
      "2008-02-12 00:00:00 174\n",
      "2008-02-26 00:00:00 263\n",
      "2008-03-11 00:00:00 297\n",
      "2008-03-25 00:00:00 340\n",
      "2008-04-08 00:00:00 303\n",
      "2008-04-22 00:00:00 258\n",
      "2008-05-06 00:00:00 232\n",
      "2008-05-20 00:00:00 212\n",
      "2008-06-03 00:00:00 244\n",
      "2008-06-17 00:00:00 270\n",
      "2008-07-01 00:00:00 247\n",
      "2008-07-15 00:00:00 268\n",
      "2008-07-29 00:00:00 591\n",
      "2008-08-12 00:00:00 234\n",
      "2008-08-26 00:00:00 194\n",
      "2008-09-09 00:00:00 165\n",
      "2008-09-23 00:00:00 169\n",
      "2008-10-07 00:00:00 206\n",
      "2008-10-21 00:00:00 234\n",
      "2008-11-04 00:00:00 194\n",
      "2008-11-18 00:00:00 203\n",
      "2008-12-02 00:00:00 201\n",
      "2008-12-16 00:00:00 178\n",
      "2008-12-30 00:00:00 147\n",
      "2009-01-13 00:00:00 149\n",
      "2009-01-27 00:00:00 557\n",
      "2009-02-10 00:00:00 180\n",
      "2009-02-24 00:00:00 225\n",
      "2009-03-10 00:00:00 290\n",
      "2009-03-24 00:00:00 307\n",
      "2009-04-07 00:00:00 457\n",
      "2009-04-21 00:00:00 301\n",
      "2009-05-05 00:00:00 340\n",
      "2009-05-19 00:00:00 414\n",
      "2009-06-02 00:00:00 317\n",
      "2009-06-16 00:00:00 405\n",
      "2009-06-30 00:00:00 309\n",
      "2009-07-14 00:00:00 437\n",
      "2009-07-28 00:00:00 569\n",
      "2009-08-11 00:00:00 350\n",
      "2009-08-25 00:00:00 439\n",
      "2009-09-08 00:00:00 516\n",
      "2009-09-22 00:00:00 800\n",
      "2009-10-06 00:00:00 378\n",
      "2009-10-20 00:00:00 310\n",
      "2009-11-03 00:00:00 403\n",
      "2009-11-17 00:00:00 199\n",
      "2009-12-01 00:00:00 438\n",
      "2009-12-15 00:00:00 170\n",
      "2009-12-29 00:00:00 144\n",
      "2010-01-12 00:00:00 145\n",
      "2010-01-26 00:00:00 404\n",
      "2010-02-09 00:00:00 381\n",
      "2010-02-23 00:00:00 183\n",
      "2010-03-09 00:00:00 238\n",
      "2010-03-23 00:00:00 203\n",
      "2010-04-06 00:00:00 217\n",
      "2010-04-20 00:00:00 238\n",
      "2010-05-04 00:00:00 221\n",
      "2010-05-18 00:00:00 250\n",
      "2010-06-01 00:00:00 233\n",
      "2010-06-15 00:00:00 326\n",
      "2010-06-29 00:00:00 613\n",
      "2010-07-13 00:00:00 838\n",
      "2010-07-27 00:00:00 571\n",
      "2010-08-10 00:00:00 437\n",
      "2010-08-24 00:00:00 376\n",
      "2010-09-07 00:00:00 859\n",
      "2010-09-21 00:00:00 253\n",
      "2010-10-05 00:00:00 592\n",
      "2010-10-19 00:00:00 530\n",
      "2010-11-02 00:00:00 495\n",
      "2010-11-16 00:00:00 588\n",
      "2010-11-30 00:00:00 563\n",
      "2010-12-14 00:00:00 632\n",
      "2010-12-28 00:00:00 508\n",
      "2008-01-01 00:00:00 230\n",
      "2008-01-15 00:00:00 179\n",
      "2008-01-29 00:00:00 239\n",
      "2008-02-12 00:00:00 232\n",
      "2008-02-26 00:00:00 236\n",
      "2008-03-11 00:00:00 325\n",
      "2008-03-25 00:00:00 276\n",
      "2008-04-08 00:00:00 271\n",
      "2008-04-22 00:00:00 237\n",
      "2008-05-06 00:00:00 272\n",
      "2008-05-20 00:00:00 228\n",
      "2008-06-03 00:00:00 203\n",
      "2008-06-17 00:00:00 258\n",
      "2008-07-01 00:00:00 188\n",
      "2008-07-15 00:00:00 275\n",
      "2008-07-29 00:00:00 292\n",
      "2008-08-12 00:00:00 197\n",
      "2008-08-26 00:00:00 219\n",
      "2008-09-09 00:00:00 299\n",
      "2008-09-23 00:00:00 398\n",
      "2008-10-07 00:00:00 207\n",
      "2008-10-21 00:00:00 225\n",
      "2008-11-04 00:00:00 192\n",
      "2008-11-18 00:00:00 299\n",
      "2008-12-02 00:00:00 180\n",
      "2008-12-16 00:00:00 262\n",
      "2008-12-30 00:00:00 155\n",
      "2009-01-13 00:00:00 295\n",
      "2009-01-27 00:00:00 289\n",
      "2009-02-10 00:00:00 234\n",
      "2009-02-24 00:00:00 328\n",
      "2009-03-10 00:00:00 205\n",
      "2009-03-24 00:00:00 292\n",
      "2009-04-07 00:00:00 540\n",
      "2009-04-21 00:00:00 317\n",
      "2009-05-05 00:00:00 341\n",
      "2009-05-19 00:00:00 500\n",
      "2009-06-02 00:00:00 318\n",
      "2009-06-16 00:00:00 270\n",
      "2009-06-30 00:00:00 290\n",
      "2009-07-14 00:00:00 413\n",
      "2009-07-28 00:00:00 413\n",
      "2009-08-11 00:00:00 381\n",
      "2009-08-25 00:00:00 334\n",
      "2009-09-08 00:00:00 453\n",
      "2009-09-22 00:00:00 802\n",
      "2009-10-06 00:00:00 476\n",
      "2009-10-20 00:00:00 315\n",
      "2009-11-03 00:00:00 243\n",
      "2009-11-17 00:00:00 352\n",
      "2009-12-01 00:00:00 523\n",
      "2009-12-15 00:00:00 237\n",
      "2009-12-29 00:00:00 157\n",
      "2010-01-12 00:00:00 181\n",
      "2010-01-26 00:00:00 282\n",
      "2010-02-09 00:00:00 308\n",
      "2010-02-23 00:00:00 331\n",
      "2010-03-09 00:00:00 324\n",
      "2010-03-23 00:00:00 189\n",
      "2010-04-06 00:00:00 311\n",
      "2010-04-20 00:00:00 364\n",
      "2010-05-04 00:00:00 305\n",
      "2010-05-18 00:00:00 344\n",
      "2010-06-01 00:00:00 333\n",
      "2010-06-15 00:00:00 395\n",
      "2010-06-29 00:00:00 975\n",
      "2010-07-13 00:00:00 1242\n",
      "2010-07-27 00:00:00 584\n",
      "2010-08-10 00:00:00 473\n",
      "2010-08-24 00:00:00 527\n",
      "2010-09-07 00:00:00 1106\n",
      "2010-09-21 00:00:00 409\n",
      "2010-10-05 00:00:00 345\n",
      "2010-10-19 00:00:00 335\n",
      "2010-11-02 00:00:00 300\n",
      "2010-11-16 00:00:00 353\n",
      "2010-11-30 00:00:00 224\n",
      "2010-12-14 00:00:00 316\n",
      "2010-12-28 00:00:00 247\n",
      "2008-01-01 00:00:00 192\n",
      "2008-01-15 00:00:00 292\n",
      "2008-01-29 00:00:00 448\n",
      "2008-02-12 00:00:00 220\n",
      "2008-02-26 00:00:00 238\n",
      "2008-03-11 00:00:00 297\n",
      "2008-03-25 00:00:00 247\n",
      "2008-04-08 00:00:00 235\n",
      "2008-04-22 00:00:00 150\n",
      "2008-05-06 00:00:00 190\n",
      "2008-05-20 00:00:00 183\n",
      "2008-06-03 00:00:00 239\n",
      "2008-06-17 00:00:00 271\n",
      "2008-07-01 00:00:00 177\n",
      "2008-07-15 00:00:00 224\n",
      "2008-07-29 00:00:00 196\n",
      "2008-08-12 00:00:00 160\n",
      "2008-08-26 00:00:00 198\n",
      "2008-09-09 00:00:00 262\n",
      "2008-09-23 00:00:00 183\n",
      "2008-10-07 00:00:00 205\n",
      "2008-10-21 00:00:00 192\n",
      "2008-11-04 00:00:00 238\n",
      "2008-11-18 00:00:00 252\n",
      "2008-12-02 00:00:00 252\n",
      "2008-12-16 00:00:00 266\n",
      "2008-12-30 00:00:00 332\n",
      "2009-01-13 00:00:00 454\n",
      "2009-01-27 00:00:00 336\n",
      "2009-02-10 00:00:00 277\n",
      "2009-02-24 00:00:00 275\n",
      "2009-03-10 00:00:00 239\n",
      "2009-03-24 00:00:00 158\n",
      "2009-04-07 00:00:00 271\n",
      "2009-04-21 00:00:00 173\n",
      "2009-05-05 00:00:00 258\n",
      "2009-05-19 00:00:00 315\n",
      "2009-06-02 00:00:00 220\n",
      "2009-06-16 00:00:00 210\n",
      "2009-06-30 00:00:00 159\n",
      "2009-07-14 00:00:00 333\n",
      "2009-07-28 00:00:00 338\n",
      "2009-08-11 00:00:00 313\n",
      "2009-08-25 00:00:00 415\n",
      "2009-09-08 00:00:00 444\n",
      "2009-09-22 00:00:00 750\n",
      "2009-10-06 00:00:00 226\n",
      "2009-10-20 00:00:00 451\n",
      "2009-11-03 00:00:00 309\n",
      "2009-11-17 00:00:00 316\n",
      "2009-12-01 00:00:00 445\n",
      "2009-12-15 00:00:00 221\n",
      "2009-12-29 00:00:00 282\n",
      "2010-01-12 00:00:00 729\n",
      "2010-01-26 00:00:00 830\n",
      "2010-02-09 00:00:00 572\n",
      "2010-02-23 00:00:00 708\n",
      "2010-03-09 00:00:00 360\n",
      "2010-03-23 00:00:00 334\n",
      "2010-04-06 00:00:00 323\n",
      "2010-04-20 00:00:00 361\n",
      "2010-05-04 00:00:00 356\n",
      "2010-05-18 00:00:00 359\n",
      "2010-06-01 00:00:00 359\n",
      "2010-06-15 00:00:00 374\n",
      "2010-06-29 00:00:00 488\n",
      "2010-07-13 00:00:00 703\n",
      "2010-07-27 00:00:00 663\n",
      "2010-08-10 00:00:00 372\n",
      "2010-08-24 00:00:00 462\n",
      "2010-09-07 00:00:00 745\n",
      "2010-09-21 00:00:00 370\n",
      "2010-10-05 00:00:00 439\n",
      "2010-10-19 00:00:00 427\n",
      "2010-11-02 00:00:00 308\n",
      "2010-11-16 00:00:00 420\n",
      "2010-11-30 00:00:00 425\n",
      "2010-12-14 00:00:00 533\n",
      "2010-12-28 00:00:00 318\n",
      "2008-01-01 00:00:00 205\n",
      "2008-01-15 00:00:00 224\n",
      "2008-01-29 00:00:00 288\n",
      "2008-02-12 00:00:00 261\n",
      "2008-02-26 00:00:00 359\n",
      "2008-03-11 00:00:00 376\n",
      "2008-03-25 00:00:00 307\n",
      "2008-04-08 00:00:00 478\n",
      "2008-04-22 00:00:00 375\n",
      "2008-05-06 00:00:00 232\n",
      "2008-05-20 00:00:00 365\n",
      "2008-06-03 00:00:00 367\n",
      "2008-06-17 00:00:00 362\n",
      "2008-07-01 00:00:00 291\n",
      "2008-07-15 00:00:00 322\n",
      "2008-07-29 00:00:00 364\n",
      "2008-08-12 00:00:00 296\n",
      "2008-08-26 00:00:00 268\n",
      "2008-09-09 00:00:00 454\n",
      "2008-09-23 00:00:00 357\n",
      "2008-10-07 00:00:00 269\n",
      "2008-10-21 00:00:00 326\n",
      "2008-11-04 00:00:00 269\n",
      "2008-11-18 00:00:00 243\n",
      "2008-12-02 00:00:00 308\n",
      "2008-12-16 00:00:00 378\n",
      "2008-12-30 00:00:00 178\n",
      "2009-01-13 00:00:00 343\n",
      "2009-01-27 00:00:00 350\n",
      "2009-02-10 00:00:00 286\n",
      "2009-02-24 00:00:00 385\n",
      "2009-03-10 00:00:00 325\n",
      "2009-03-24 00:00:00 354\n",
      "2009-04-07 00:00:00 462\n",
      "2009-04-21 00:00:00 311\n",
      "2009-05-05 00:00:00 277\n",
      "2009-05-19 00:00:00 408\n",
      "2009-06-02 00:00:00 405\n",
      "2009-06-16 00:00:00 348\n",
      "2009-06-30 00:00:00 281\n",
      "2009-07-14 00:00:00 453\n",
      "2009-07-28 00:00:00 402\n",
      "2009-08-11 00:00:00 480\n",
      "2009-08-25 00:00:00 394\n",
      "2009-09-08 00:00:00 476\n",
      "2009-09-22 00:00:00 768\n",
      "2009-10-06 00:00:00 433\n",
      "2009-10-20 00:00:00 366\n",
      "2009-11-03 00:00:00 335\n",
      "2009-11-17 00:00:00 412\n",
      "2009-12-01 00:00:00 606\n",
      "2009-12-15 00:00:00 369\n",
      "2009-12-29 00:00:00 280\n",
      "2010-01-12 00:00:00 313\n",
      "2010-01-26 00:00:00 504\n",
      "2010-02-09 00:00:00 395\n",
      "2010-02-23 00:00:00 354\n",
      "2010-03-09 00:00:00 401\n",
      "2010-03-23 00:00:00 308\n",
      "2010-04-06 00:00:00 300\n",
      "2010-04-20 00:00:00 441\n",
      "2010-05-04 00:00:00 420\n",
      "2010-05-18 00:00:00 469\n",
      "2010-06-01 00:00:00 418\n",
      "2010-06-15 00:00:00 987\n",
      "2010-06-29 00:00:00 1805\n",
      "2010-07-13 00:00:00 1728\n",
      "2010-07-27 00:00:00 852\n",
      "2010-08-10 00:00:00 570\n",
      "2010-08-24 00:00:00 588\n",
      "2010-09-07 00:00:00 1508\n",
      "2010-09-21 00:00:00 608\n",
      "2010-10-05 00:00:00 387\n",
      "2010-10-19 00:00:00 522\n",
      "2010-11-02 00:00:00 396\n",
      "2010-11-16 00:00:00 412\n",
      "2010-11-30 00:00:00 422\n",
      "2010-12-14 00:00:00 360\n",
      "2010-12-28 00:00:00 315\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "drug_dictionary={}\n",
    "\n",
    "#for each drug create an empty dictionary\n",
    "for drug in drugs:\n",
    "\n",
    "    start= datetime.datetime(2008, 01, 01)\n",
    "    delta =  datetime.timedelta(weeks=2)\n",
    "    stop = start+delta\n",
    "\n",
    "    data=[]\n",
    "    i=0;\n",
    "\n",
    "    while start.year<2011:\n",
    "        eventlist=get_event_data(drug, start.strftime('%Y-%m-%d'), stop.strftime('%Y-%m-%d'))\n",
    "        time.sleep(0.25)\n",
    "        total=get_total_adverse_events(eventlist)\n",
    "        print str(start)+\" \"+str(total)\n",
    "        year=start.year\n",
    "        entry={}\n",
    "        \n",
    "        entry['event_count']=total\n",
    "        entry['date']=start\n",
    "        data.append(entry)\n",
    "        i=i+1\n",
    "        start=stop\n",
    "        stop=start+delta\n",
    "        \n",
    "    drug_dictionary[drug]=data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we save the data using the json format.  This is important.  Retreiving large amounts of data can be time consuming and error prone.  The API might not be reachable next time, or may change.  We could demo our software at a new site, on a different network and a firewall could prevent us from connecting.  So it is a good idea to save the data locally and only use the API if we want to rerieve data using different parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "datetime.datetime(2008, 1, 1, 0, 0) is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1fd134dc3207>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'drug_events.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mjs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrug_dictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bnorthan\\Anaconda\\lib\\json\\__init__.pyc\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, encoding, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;31m# a debuggability cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bnorthan\\Anaconda\\lib\\json\\encoder.pyc\u001b[0m in \u001b[0;36m_iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bnorthan\\Anaconda\\lib\\json\\encoder.pyc\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    406\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bnorthan\\Anaconda\\lib\\json\\encoder.pyc\u001b[0m in \u001b[0;36m_iterencode_list\u001b[1;34m(lst, _current_indent_level)\u001b[0m\n\u001b[0;32m    330\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bnorthan\\Anaconda\\lib\\json\\encoder.pyc\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    406\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bnorthan\\Anaconda\\lib\\json\\encoder.pyc\u001b[0m in \u001b[0;36m_iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    440\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Circular reference detected\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m             \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bnorthan\\Anaconda\\lib\\json\\encoder.pyc\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \"\"\"\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" is not JSON serializable\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: datetime.datetime(2008, 1, 1, 0, 0) is not JSON serializable"
     ]
    }
   ],
   "source": [
    "with open('drug_events.json', 'wb') as fp:\n",
    "    js.dump(drug_dictionary, fp)\n",
    "    \n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did not generate the data using the openFDA api you can open the data at this step.  If you did generate the data and save it, it is good practice to reopen it and verify the file saved properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listPaxil=drug_dictionary['paxil']#[0]['date']\n",
    "listHydrocodone=drug_dictionary['hydrocodone']\n",
    "listLexapro=drug_dictionary['lexapro']\n",
    "listXanax=drug_dictionary['xanax']\n",
    "\n",
    "dataList=[]\n",
    "print drug_dictionary.keys()\n",
    "\n",
    "for i in range(0,len(listPaxil)):\n",
    "    dataList.append([listPaxil[i]['date'],listPaxil[i]['event_count'],listHydrocodone[i]['event_count'],listLexapro[i]['event_count'],listXanax[i]['event_count']])\n",
    "\n",
    "print len(dataList)\n",
    "print dataList[45]\n",
    "\n",
    "import csv\n",
    "fw=open('drugEvents.csv', 'wb')\n",
    "csvw=csv.writer(fw, delimiter=',')\n",
    "for row in dataList:\n",
    "    csvw.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=drug_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('drug_events.json', 'rb') as fp:\n",
    "    data = js.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a function to smooth our data.  This one is taken from the scipy cookbook.  A complete explation of the function is beyond the scope of this lesson but can be found here http://wiki.scipy.org/Cookbook/SignalSmooth.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def smooth(x,window_len=11,window='hanning'):\n",
    "        if x.ndim != 1:\n",
    "                raise ValueError, \"smooth only accepts 1 dimension arrays.\"\n",
    "        if x.size < window_len:\n",
    "                raise ValueError, \"Input vector needs to be bigger than window size.\"\n",
    "        if window_len<3:\n",
    "                return x\n",
    "        if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "                raise ValueError, \"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\"\n",
    "        s=np.r_[2*x[0]-x[window_len-1::-1],x,2*x[-1]-x[-1:-window_len:-1]]\n",
    "        if window == 'flat': #moving average\n",
    "                w=np.ones(window_len,'d')\n",
    "        else:  \n",
    "                w=eval('np.'+window+'(window_len)')\n",
    "        y=np.convolve(w/w.sum(),s,mode='same')\n",
    "        return y[window_len:-window_len+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data let's start plotting.  First we'll create a simple line plot.  Before plotting we need to check what type of data we have.  We should have a dictionary where the keys are drug names.  So lets verify that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We stored the drug names as a list.  This was done to make it easy to analyze data for a different set of drugs (we only have to change the list).  For each drug we stored a list of dictionaries with keys 'date' and 'event_count'.  It can be a bit confusing so once again lets verify the data is as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(data[drugs[0]])\n",
    "print type(data[drugs[0]][0])\n",
    "\n",
    "for key, value in data[drugs[0]][0].iteritems():\n",
    "    print key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the data we need to convert the list of dictionary entries to a list of numbers.  So lets do that for the first drug and plot the data.  We use the numpy 'arange' function to create x axis values based on the length of our y data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drug_name=drugs[0]\n",
    "\n",
    "y=[]\n",
    "\n",
    "for entry in data[drug_name]:\n",
    "        y.append( entry['event_count'] )\n",
    "\n",
    "\n",
    "x=np.arange(len(y))\n",
    "plt.plot(x, y)\n",
    "plt.title('Weekly adverse events for '+drug_name)\n",
    "plt.ylabel('Adverse Events')\n",
    "plt.xlabel('Week')\n",
    "\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(figsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also loop and create a line graph for all the drugs.   Notice that we pass a third input to the plot function called 'label'.  By passing in a label we create an association between each line style and that label which is later used when rendering the legend.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for drug in drugs:\n",
    "    event_list=[]\n",
    "    for entry in data[drug]:\n",
    "        event_list.append( entry['event_count'] )\n",
    "    x=np.arange(len(event_list))\n",
    "    plt.plot(x, event_list, label=drug)\n",
    "    \n",
    "plt.title('Weekly adverse events')\n",
    "plt.ylabel('Adverse Events')\n",
    "plt.xlabel('Week')\n",
    "\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(figsize)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is very noisy with spikes that appear correlated.  This time we smooth the data before plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smoothed_data={}\n",
    "\n",
    "for drug in drugs:\n",
    "    event_list=[]\n",
    "    \n",
    "    for entry in data[drug]:\n",
    "        event_list.append( entry['event_count'] )\n",
    "    smoothed=smooth(np.array(event_list),50)\n",
    "    x=np.arange(len(smoothed))\n",
    "    plt.plot(x, smoothed, label=drug)\n",
    "    print drug\n",
    "    smoothed_data[drug]=smoothed\n",
    "    \n",
    "plt.title('Weekly adverse events for '+drug_name)\n",
    "plt.ylabel('Adverse Events')\n",
    "plt.xlabel('Week')\n",
    "plt.legend()\n",
    "\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(figsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be a bit difficult to perceive relative changes between the plots.  We can use a stacked area chart to look at relative and absolute differences.  (http://stackoverflow.com/questions/2225995/how-can-i-create-stacked-line-graph-with-matplotlib).  It's a bit tricky to get the legend to appear properly but it's covered in this stack-overflow question http://stackoverflow.com/questions/20336881/matplotlib-stackplot-legend-error.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "y=np.row_stack(( np.array(smoothed_data[drugs[0]]), np.array(smoothed_data[drugs[1]]), np.array(smoothed_data[drugs[2]])))\n",
    "\n",
    "y_stack=np.cumsum(y, axis=0)\n",
    "\n",
    "x=np.arange(len(smoothed_data[drugs[0]]))\n",
    "\n",
    "stacks=ax1.stackplot(x, y_stack, label=drugs)\n",
    "\n",
    "plt.title('Weekly adverse events for '+drug_name)\n",
    "plt.ylabel('Adverse Events')\n",
    "plt.xlabel('Week')\n",
    "\n",
    "proxy_rects = [mpatches.Rectangle((0, 0), 1, 1, fc=pc.get_facecolor()[0]) for pc in stacks]\n",
    "ax1.legend(proxy_rects, drugs)\n",
    "\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(figsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a stacked 100% area chart to look at only relative differences.  In this case the 100% stacked area chart is very useful since the data has correlated peaks.  The stacked 100% area chart emphasizes uncorrelated trends.  http://stackoverflow.com/questions/16875546/create-a-100-stacked-area-chart-with-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent = y_stack /  y_stack.sum(axis=0).astype(float) * 100 \n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.stackplot(x, percent)\n",
    "\n",
    "plt.title('Weekly adverse events for '+drug_name)\n",
    "plt.ylabel('Adverse Events')\n",
    "plt.xlabel('Week')\n",
    "\n",
    "proxy_rects = [mpatches.Rectangle((0, 0), 1, 1, fc=pc.get_facecolor()[0]) for pc in stacks]\n",
    "ax1.legend(proxy_rects, drugs)\n",
    "\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(figsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
